{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb.fs.full.training as training\n",
    "import ipynb.fs.full.splitting as splitting\n",
    "import ipynb.fs.full.misc as misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENSEMBLE CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class create_ensemble():\n",
    "    \n",
    "    # STATIC VARS\n",
    "    def __init__(self, _settings):\n",
    "        self.settings = _settings\n",
    "        self.models = []\n",
    "    \n",
    "    # ADD A MODEL TO THE ENSEMBLE\n",
    "    def add_model(self, model):\n",
    "        models.add(model)\n",
    "\n",
    "    # PREDICT WITH ALL ENSEMBLE MODELS\n",
    "    def predict(self, dataset):\n",
    "        \n",
    "        # CREATE NEW DATAFRAME\n",
    "        dataframe = pd.DataFrame()\n",
    "        \n",
    "        # LOOP THROUGH MODELS\n",
    "        for model in self.models:\n",
    "            \n",
    "            # FETCH AVERAGE PREDICTION FROM CV MODELS\n",
    "            if type(model) == 'list':\n",
    "                collection = []\n",
    "                \n",
    "                for sub_model in model:\n",
    "                    predictions = sub_model.predict(dataset)\n",
    "                    collection.append(predictions)\n",
    "                    \n",
    "                # TRANSPOSE & CALCULATE AVERAGE PER ROW\n",
    "                averages = collections.transpose().mean()\n",
    "                \n",
    "                # PUSH TO DATAFRAME\n",
    "                dataframe[model[0].name] = averages\n",
    "            \n",
    "            # OTHERWISE, PREDICT NORMALLY\n",
    "            else:\n",
    "                predictions = model.predict(dataset)\n",
    "                dataframe[model.name] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REGRESSION ENSEMBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(primary_dataset, config):\n",
    "    \n",
    "    # REQUESTED MODELS\n",
    "    models = config['regression_ensemble']['models']\n",
    "    \n",
    "    # ENSEMBLE CONTAINER\n",
    "    ensemble = [None] * len(models)\n",
    "    \n",
    "    # LOOP THROUGH MODELS\n",
    "    for index, item in enumerate(models):\n",
    "\n",
    "        # MODEL PROPS\n",
    "        name, settings = misc.key_value(item)\n",
    "\n",
    "        # FOLD CONTAINER\n",
    "        folds = []\n",
    "\n",
    "        # IF THE MODEL HAS EXTRA SETTINGS\n",
    "        if settings:\n",
    "            folds = splitting.timeseries(\n",
    "                primary_dataset['train'],\n",
    "                config['splitting']['validation_folds'],\n",
    "                window=settings['morph']['window']\n",
    "            )\n",
    "\n",
    "        # OTHERWISE\n",
    "        else:\n",
    "            folds = splitting.timeseries(\n",
    "                primary_dataset['train'],\n",
    "                config['splitting']['validation_folds']\n",
    "            )\n",
    "\n",
    "        # FOLD DATA\n",
    "        temp_predictions = []\n",
    "        temp_labels = []\n",
    "        temp_models = []\n",
    "\n",
    "        # LOOP THROUGH FOLDS\n",
    "        for fold_index, fold in enumerate(folds):\n",
    "            \n",
    "            # PRINT A MESSAGE\n",
    "            print('TRAINING {} FOLD #{}'.format(name.upper(), fold_index + 1))\n",
    "            \n",
    "            # TRAIN & PREDICT WITH THE MODEL\n",
    "            model, predictions, labels = training.start(fold, name, settings)\n",
    "\n",
    "            # APPEND TO COLLECTIONS\n",
    "            temp_models.append(model)\n",
    "            temp_predictions.append(predictions)\n",
    "            temp_labels.append(labels)\n",
    "\n",
    "        # APPEND RESULTS TO ENSEMBLE\n",
    "        ensemble[index] = {\n",
    "            'name': '{}_{}'.format(name, index),\n",
    "            'predictions': np.concatenate(temp_predictions),\n",
    "            'labels': np.concatenate(temp_labels),\n",
    "            'models': temp_models\n",
    "        }\n",
    "        \n",
    "        # PRINT A SPACE WHEN NECESSARY\n",
    "        if index < len(models) -1:\n",
    "            print()\n",
    "    \n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSIFIER ENSEMBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(secondary_dataset, config):\n",
    "    \n",
    "    # REQUESTED MODELS\n",
    "    models = config['classification_ensemble']['models']\n",
    "    \n",
    "    # ENSEMBLE CONTAINER\n",
    "    ensemble = [None] * len(models)\n",
    "\n",
    "    # LOOP THROUGH MODELS\n",
    "    for index, item in enumerate(config['classification_ensemble']['models']):\n",
    "\n",
    "        # MODEL PARAMS\n",
    "        name, settings = misc.key_value(item)\n",
    "        \n",
    "        # PRINT A MESSAGE\n",
    "        print('TRAINING {} MODEL'.format(name.upper()))\n",
    "        \n",
    "        # SCALE THE DATASET FEATUERS\n",
    "        scaled_dataset, scaler = normalize(secondary_dataset)\n",
    "\n",
    "        # TRAIN & PREDICT WITH THE MODEL\n",
    "        model, predictions = training.start(scaled_dataset, name, settings)\n",
    "\n",
    "        # APPEND RESULTS TO ENSEMBLE\n",
    "        ensemble[index] = {\n",
    "            'name': '{}_{}'.format(name, index),\n",
    "            'predictions': predictions,\n",
    "            'labels': secondary_dataset['test']['labels'],\n",
    "            'scaler': scaler\n",
    "        }\n",
    "    \n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
